"""Priority Living CLI â€” System diagnostics (status & diagnose)."""

import json
import os
import platform
import shutil
import sys
import time
import urllib.request
import urllib.error
from pathlib import Path

from priority_living import __version__
from priority_living.config_manager import load_config


def handle_status(default_backend, default_anon_key):
    cfg = load_config()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘  Priority Living CLI  v{__version__:<18}â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    
    # System
    print(f"â•‘  ğŸ–¥  Machine:  {platform.node():<26}â•‘")
    print(f"â•‘  ğŸ Python:   {sys.version.split()[0]:<26}â•‘")
    print(f"â•‘  ğŸ’» OS:       {platform.system()} {platform.release():<17}â•‘")
    
    # Disk
    disk = shutil.disk_usage(str(Path.home()))
    free_gb = round(disk.free / (1024**3), 1)
    print(f"â•‘  ğŸ’¾ Disk:     {free_gb} GB free{' ' * (20 - len(str(free_gb)))}â•‘")
    
    # GPU
    gpu_status = _check_gpu()
    print(f"â•‘  ğŸ® GPU:      {gpu_status:<26}â•‘")
    
    # Dependencies
    deps = _check_deps()
    print(f"â•‘  ğŸ“¦ Deps:     {deps:<26}â•‘")
    
    # Bridge
    bridge_key = cfg.get("bridge_key", "")
    if bridge_key:
        bridge_status = _check_bridge(bridge_key, cfg.get("backend_url", default_backend), cfg.get("anon_key", default_anon_key))
        print(f"â•‘  ğŸ”— Bridge:   {bridge_status:<26}â•‘")
    else:
        print(f"â•‘  ğŸ”— Bridge:   {'Not configured':<26}â•‘")
    
    # Models
    models = _list_local_models()
    print(f"â•‘  ğŸ§  Models:   {len(models)} installed{' ' * (17 - len(str(len(models))))}â•‘")
    
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


def handle_diagnose(default_backend, default_anon_key):
    cfg = load_config()
    print("ğŸ” Running deep diagnostic scan...\n")
    
    issues = []
    
    # 1. Python version
    v = sys.version_info
    if v.major < 3 or (v.major == 3 and v.minor < 7):
        issues.append("âŒ Python 3.7+ required")
    else:
        print(f"  âœ… Python {v.major}.{v.minor}.{v.micro}")
    
    # 2. GPU
    gpu = _check_gpu_detailed()
    if gpu["available"]:
        print(f"  âœ… GPU: {gpu['name']}")
    else:
        print(f"  âš ï¸  No GPU detected (CPU-only inference)")
    
    # 3. Dependencies
    for pkg in ["requests", "torch", "transformers", "huggingface_hub"]:
        try:
            __import__(pkg)
            print(f"  âœ… {pkg} installed")
        except ImportError:
            print(f"  âš ï¸  {pkg} not installed")
    
    # 4. Bridge key
    bridge_key = cfg.get("bridge_key", "")
    if not bridge_key:
        issues.append("âŒ No bridge key configured. Run: pl config set bridge_key pb_xxx")
        print("  âŒ Bridge key: not set")
    elif not bridge_key.startswith("pb_"):
        issues.append("âŒ Invalid bridge key format")
        print("  âŒ Bridge key: invalid format")
    else:
        print("  âœ… Bridge key: configured")
    
    # 5. Network connectivity
    backend = cfg.get("backend_url", default_backend)
    try:
        start = time.time()
        req = urllib.request.Request(f"{backend}/functions/v1/bridge-poll", method="OPTIONS")
        req.add_header("Origin", "https://test.local")
        with urllib.request.urlopen(req, timeout=10) as resp:
            latency = round((time.time() - start) * 1000)
            print(f"  âœ… Backend reachable ({latency}ms latency)")
    except Exception as e:
        issues.append(f"âŒ Cannot reach backend: {e}")
        print(f"  âŒ Backend unreachable: {e}")
    
    # 6. Models directory
    models_dir = Path.home() / ".priority-living" / "models"
    if models_dir.exists():
        models = [d.name for d in models_dir.iterdir() if d.is_dir()]
        print(f"  âœ… Models directory: {len(models)} models")
    else:
        print("  â„¹ï¸  Models directory not created yet")
    
    # Summary
    print()
    if issues:
        print(f"âš ï¸  {len(issues)} issue(s) found:")
        for i in issues:
            print(f"   {i}")
    else:
        print("âœ… All checks passed! System is ready.")


def _check_gpu():
    try:
        import torch
        if torch.cuda.is_available():
            return torch.cuda.get_device_name(0)[:26]
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            return "Apple Silicon (MPS)"
        return "CPU only"
    except ImportError:
        return "torch not installed"


def _check_gpu_detailed():
    try:
        import torch
        if torch.cuda.is_available():
            return {"available": True, "name": torch.cuda.get_device_name(0), "type": "cuda"}
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            return {"available": True, "name": "Apple Silicon (MPS)", "type": "mps"}
        return {"available": False, "name": "CPU only", "type": "cpu"}
    except ImportError:
        return {"available": False, "name": "torch not installed", "type": "none"}


def _check_deps():
    installed = []
    for pkg in ["torch", "transformers", "huggingface_hub"]:
        try:
            __import__(pkg)
            installed.append(pkg.split("_")[0][:4])
        except ImportError:
            pass
    return f"{len(installed)}/3 AI pkgs" if installed else "None installed"


def _check_bridge(key, backend, anon_key):
    try:
        url = f"{backend}/functions/v1/bridge-poll"
        headers = {
            "Content-Type": "application/json",
            "apikey": anon_key,
            "Authorization": f"Bearer {anon_key}",
            "x-bridge-key": key,
        }
        data = json.dumps({"machine_name": "diag-check"}).encode()
        req = urllib.request.Request(url, data=data, headers=headers, method="POST")
        with urllib.request.urlopen(req, timeout=10):
            return "Connected âœ…"
    except urllib.error.HTTPError as e:
        if e.code == 401:
            return "Invalid key âŒ"
        return f"Error ({e.code})"
    except Exception:
        return "Unreachable"


def _list_local_models():
    models_dir = Path.home() / ".priority-living" / "models"
    if not models_dir.exists():
        return []
    return [d.name for d in models_dir.iterdir() if d.is_dir()]
